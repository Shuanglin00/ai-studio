import dev.langchain4j.data.document.Document;
import dev.langchain4j.data.document.DocumentSplitter;
import dev.langchain4j.data.document.splitter.DocumentSplitters;

public class documentTest {
    public static void main(String[] args) {
        String str ="RAG 是 **Retrieval Augmented Generation** 的缩写，中文通常翻译为**检索增强生成**。\n" +
                "\n" +
                "---\n" +
                "\n" +
                "### 什么是 RAG？\n" +
                "\n" +
                "简单来说，RAG 是一种结合了**信息检索**和**大型语言模型（LLM）**的技术。它解决了传统 LLM 存在的两个主要问题：\n" +
                "\n" +
                "1.  **知识时效性不足：** LLM 在训练后，其知识就固定了。对于训练数据之后发生的新信息，或者非常专业、小众领域的知识，LLM 无法直接回答。\n" +
                "2.  **“幻觉”问题：** LLM 有时会“胡编乱造”信息，给出听起来很合理但实际上是错误的答案。\n" +
                "\n" +
                "RAG 的核心思想是，在 LLM 生成回答之前，先从一个**外部的、权威的知识库**中检索出与用户问题最相关的信息，然后把这些检索到的信息作为**额外的上下文**提供给 LLM，让 LLM 基于这些**最新、准确的外部知识**来生成回答。\n" +
                "\n" +
                "你可以把它想象成：给一个本来很聪明的学生（LLM）提供一本**可以实时查阅的参考书**（外部知识库），这样他在回答问题时就不会只凭记忆，而是可以查阅最新、最准确的资料。\n" +
                "\n" +
                "---\n" +
                "\n" +
                "### RAG 的工作原理\n" +
                "\n" +
                "RAG 的工作流程通常包含以下几个步骤：\n" +
                "\n" +
                "1.  **准备知识库（索引阶段）：**\n" +
                "    * 首先，你需要将你的**私有数据、文档、网页信息**等整理成一个知识库。\n" +
                "    * 这些数据会被分割成更小的、可管理的**片段**（chunk）。\n" +
                "    * 然后，利用**嵌入模型（embedding model）**将这些文本片段转换成**向量（Vector）**形式。向量是文本在多维空间中的数字表示，语义相似的文本片段，它们的向量距离会比较近。\n" +
                "    * 这些向量会存储在**向量数据库**中，以便快速高效地检索。\n" +
                "\n" +
                "2.  **检索相关信息（检索阶段）：**\n" +
                "    * 当用户提出一个问题时，这个用户问题也会被转换成一个**向量**。\n" +
                "    * RAG 系统会在向量数据库中，寻找与用户问题向量**最相似（语义上最相关）**的文档片段向量。\n" +
                "    * 这些被检索到的相关文档片段就是 LLM 将要引用的“参考资料”。\n" +
                "\n" +
                "3.  **增强提示并生成回答（生成阶段）：**\n" +
                "    * RAG 系统将用户的原始问题与检索到的**相关文档片段**结合起来，形成一个**增强的提示（augmented prompt）**。\n" +
                "    * 这个增强的提示（包含了问题和参考资料）被发送给大型语言模型。\n" +
                "    * LLM 结合其自身已有的知识和这个提供的**额外上下文**，生成最终的回答。\n" +
                "\n" +
                "---\n" +
                "\n" +
                "### RAG 的主要优势\n" +
                "\n" +
                "* **提高准确性和相关性：** 通过引入外部知识，LLM 的回答不再局限于其训练数据，而是可以提供更准确、最新和与用户问题高度相关的答案，有效减少“幻觉”。\n" +
                "* **知识可更新性强：** 知识库可以独立于 LLM 进行更新，不需要重新训练整个大型模型，大大降低了维护成本和时间。\n" +
                "* **降低成本：** 相对于对 LLM 进行微调（Fine-tuning）或预训练，RAG 是一种更经济、更高效地让 LLM 掌握特定领域知识的方法。\n" +
                "* **增强可信度：** RAG 系统通常可以提供其回答所引用的**来源信息**，让用户可以追溯和验证答案的真实性，增强用户信任。\n" +
                "* **对开发者的控制力更强：** 开发者可以控制 LLM 检索的信息来源，更容易测试和改进应用程序。\n" +
                "\n" +
                "---\n" +
                "\n" +
                "### RAG 的应用场景\n" +
                "\n" +
                "RAG 技术非常适合以下场景：\n" +
                "\n" +
                "* **企业内部知识问答系统：** 让 AI 助理能够回答基于公司内部文档、规章制度、产品手册等内容的提问。\n" +
                "* **客户服务聊天机器人：** 提供基于最新产品信息、常见问题解答（FAQ）的准确答案。\n" +
                "* **医疗信息系统：** 帮助医生或患者查询最新的医学研究、病历或诊疗指南。\n" +
                "* **研究和内容创作：** 从大量文献资料中快速提取关键信息并进行总结。\n" +
                "\n" +
                "通过 RAG，我们可以让大型语言模型变得更加实用、可靠和强大。\n" +
                "\n" +
                "你对 RAG 的哪个方面最感兴趣呢？";
        Document document = Document.from(str);
        DocumentSplitter recursive = DocumentSplitters.recursive(300, 0);
        recursive.split(document).forEach(document1->{
            System.out.println("document = " + document1);
            System.out.println();
            System.out.println();
            System.out.println();
            System.out.println();
            System.out.println();
            System.out.println();
        });
    }
}
